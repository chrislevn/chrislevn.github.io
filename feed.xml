<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://christopherle.com//feed.xml" rel="self" type="application/atom+xml"/><link href="https://christopherle.com//" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-22T13:15:12+00:00</updated><id>https://christopherle.com//feed.xml</id><title type="html">blank</title><subtitle>A software engineer with a passion for connecting all things infrastructure and data. </subtitle><entry><title type="html">My current understanding of MLOps workflow</title><link href="https://christopherle.com//blog/2023/current-understanding-mlops/" rel="alternate" type="text/html" title="My current understanding of MLOps workflow"/><published>2023-11-21T13:56:00+00:00</published><updated>2023-11-21T13:56:00+00:00</updated><id>https://christopherle.com//blog/2023/current-understanding-mlops</id><content type="html" xml:base="https://christopherle.com//blog/2023/current-understanding-mlops/"><![CDATA[<h2 id="my-current-understanding-of-mlops-workflow">My current understanding of MLOps workflow</h2> <p>This series will be about how to deploy your AI model from A to Z. Everything is based on my current understanding and learning of Machine Learning, Cloud engineering, and Full-stack development.</p> <p><strong>Why I created this blog?</strong></p> <p>As one of the ML self-taught, I have created many Machine Learning models that don’t have an API out there yet. However, none went to production. In spite of the non-technical challenges, it is hard for a data scientist to scale their Machine Learning model without the help of an ML Engineer/Software Engineer/DevOps Engineer (read more <a href="https://towardsdatascience.com/why-90-percent-of-all-machine-learning-models-never-make-it-into-production-ce7e250d5a4a">here</a>). This whole workflow of deploying ML models lay in the category of MLOps (Machine Learning Operations). That’s why I was inspired to write this blog series. My main goal is to find a deployment workflow that is scaleable and easy. In the end, I hope data scientists can worry less about scaling and focus on improving the accuracy of their models.</p> <p>Note that this first blog is an introduction so there will be no coding tutorial.</p> <p><strong>Who is this blog for?</strong></p> <ul> <li>Machine Learning practitioners/Data scientists who would like to test their ideas in production.</li> </ul> <p>However, this blog is not for a big production or if you prefer on-premise over Cloud workflow. One of the reasons I can think of when using on-premise over Cloud workflow is having sensitive data that some companies are hesitant to store on the Cloud. Another is the lack of full control in response to the convenience of easier deployment.</p> <h2 id="mlops-workflow"><strong>MLOps workflow</strong></h2> <p><img src="https://cdn-images-1.medium.com/max/2000/1*fyda87Cy6_OZIrgK3jmHEQ.png" alt="My current simple understanding of MLOPs workflow"/></p> <ol> <li><strong>Get data</strong></li> </ol> <p>There are many ways to store your data. While on-premise has advantages over control and security, Cloud Data Storage such as GCP, AWS, Azure, and MongoDB offers data storage and infrastructures that you don’t have to worry about maintaining.</p> <p>Remember that you might need data version control to keep track of changes in the dataset. Read more about data version control with DVC from this <a href="https://medium.com/geekculture/data-version-control-dvc-with-google-cloud-storage-and-python-for-ml-fe99dc7d338">blog</a>.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*k_33-imUwWHZhv2G.png" alt="*Data management middleware from dvc.org*"/></p> <p><strong>2. Visualize data</strong></p> <p>You can also easily visualize your current data on the Cloud with tools such as BigQuery from GCP, AWS QuickSight, or the Double Cloud (check my previous <a href="https://medium.com/@locvicvn1234/visualize-your-data-with-doublecloud-and-clickhouse-db-8713796389ab?postPublishedType=repub">post</a>). No need to constantly download and visualize new data.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*Vo3Rk9uez8kYYAv_" alt="Unsplash: data visualization example"/></p> <p><strong>3. Pre-processing/Clean data</strong></p> <p>Sometimes, data can come in raw like an image, text, sound, video file or as a table (.csv, excel). It’s your job to make these raw data processable for the model that you built.</p> <p>Sometimes, inputting these data can take a ton of time, considering there are many users for your app or the size of the data. Instead of having your notebook doing everything, one way to optimize this process is to have your cleaning process on Cloud using tools such as Vertex AI from GCP. The Cloud will take in your input file and return your processed input.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*7WtZCEjTqBAXtN1V.png" alt="Vertex AI logo"/></p> <ol> <li>Training model</li> </ol> <p>Lastly, training a new model, whether it’s completely new or pre-trained, can take lots of time. Having your model trained on Cloud providers will reduce the training time as well as infrastructure maintenance from your side. There are many tools for this step such as IBM Watson Studio, Databricks Lakehouse, GCP Vertex AI, etc.</p> <ol> <li>Deploying your model</li> </ol> <p>Deploying the model is also crucial so that others can make use of and test your model. This post series will focus on making your model an API. If you would like to learn how to have a front end to test your API, consider tools such as <a href="https://streamlit.io/">Streamlit</a>.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*dVTeOo1i6Q1zY4NN.png" alt="Sample Streamlit app from streamli.io"/></p> <p>From this step, every time you get new data, it can be added for visualization, processed, and tested on the deployed model.</p> <ol> <li>Model monitor</li> </ol> <p>Finally, model monitoring with tools such as <a href="https://cloud.google.com/vertex-ai/docs/model-monitoring">Vertex AI</a> is the essential step to check the accuracy of your model. It also involves of CI/CD to take in new data to be retrained and deployed on a new model.</p> <p>This is my first post on MLOps. I understand there will be a lot of things I don’t know yet so please give me any feedback. While these steps might sound a lot and vague now, I aim to make the whole process visualized and easier.</p> <p>Until then, take care! See you in the next blog post on how to deploy your ML model.</p>]]></content><author><name></name></author><category term="AI"/><category term="mlops"/><summary type="html"><![CDATA[My current understanding of MLOps workflow]]></summary></entry><entry><title type="html">What happens when you type a URL into your browser? — The big picture (with Cloud)</title><link href="https://christopherle.com//blog/2023/inside-browser/" rel="alternate" type="text/html" title="What happens when you type a URL into your browser? — The big picture (with Cloud)"/><published>2023-05-31T13:56:00+00:00</published><updated>2023-05-31T13:56:00+00:00</updated><id>https://christopherle.com//blog/2023/inside-browser</id><content type="html" xml:base="https://christopherle.com//blog/2023/inside-browser/"><![CDATA[<h2 id="what-happens-when-you-type-a-url-into-your-browser--the-big-picture-with-cloud">What happens when you type a URL into your browser? — The big picture (with Cloud)</h2> <p>Have you ever wondered what happens behind the scenes when you type a URL into your browser? It’s a simple action that we often take for granted, but the journey from entering a web address to seeing a fully-rendered website involves multiple intricate steps. In this blog, we will demystify the process and shed light on the inner workings of the internet, exploring the key stages that occur when you type a URL into your browser. I will keep it as simple as possible with 3 parts:</p> <ul> <li> <p>What is in the URL?</p> </li> <li> <p>What happens when you type a URL into your browser?</p> </li> <li> <p>How we can use cloud services such as AWS/GCP/Azure, Terraform, Kubernetes, and Docker in this example?</p> </li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2000/0*2rAkxbt_vcBiO5Qy.jpg" alt="AfterAcademy"/></p> <h2 id="what-is-in-the-url">What is in the URL?</h2> <p>The URL you entered into the address bar (for example, <a href="http://www.google.com">www.google.com</a> or <a href="https://www.google.com/">https://www.google.com</a>) contains several parts:</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*6y-4y2ygZNPwJUBEv_qHTw.png" alt=""/></p> <h2 id="protocol-https">Protocol (http/s):</h2> <p>The protocol HTTP/S (Hypertext transfer protocol/secure). HTTP is the foundation of World Wide Web and is used to load webpages using hypertext links. HTTP is used to transfer data, such as text, images, and videos, between web servers and web browsers. We use GET and POST requests to get or post content to the desired webpages via HTTP protocol.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*6H7KLCpcmSPn_WQe.png" alt="[www3.ntu.edu.sg](http://www3.ntu.edu.sg)"/></p> <p>However, HTTP is a plain text protocol, which means that the data that is transferred between the web browser and the web server is not encrypted. This means that anyone who can intercept the data, such as a hacker, can read it. HTTPS is an extension of HTTP that uses Secure Sockets Layer (SSL) or Transport Layer Security (TLS) to encrypt the data that is transferred between the web browser and the web server. This makes HTTPS much more secure than HTTP.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*Arx-OQN-L9hoh7DL.png" alt="Source: SSL Store"/></p> <p>As for SSL and TLS, they work as below:</p> <ol> <li> <p>The client (e.g., a web browser) sends a request to the server.</p> </li> <li> <p>The server sends back a certificate, which contains the server’s public key.</p> </li> <li> <p>The client uses the public key to encrypt a message, which is sent back to the server.</p> </li> <li> <p>The server uses its private key to decrypt the message.</p> </li> <li> <p>If the message is successfully decrypted, then the client and the server can communicate securely.</p> </li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/0*olTav7yi-43C2n5M.jpg" alt="Source: MDaemon Blog"/></p> <h2 id="dns-wwwgooglecom">DNS (<a href="http://www.google.com">www.google.com</a>):</h2> <p>Do you know that every single URL like <a href="http://google.com">google.com</a> has a unique IP address. For <a href="http://google.com">google.com</a>, it is 142.251.32.46. So if you enter 142.251.32.46 into your address bar, it will return <a href="http://google.com">google.com</a> site. DNS (Domain Name System) is like a phone book with a list of IP addresses and their corresponding URLs. When you enter an URL into the address bar, DNS will look for the correct IP address.</p> <p>There are 3 parts in the URLs (without HTTP/S):</p> <ul> <li> <p>www (World Wide Web) is a protocol used to access websites that are hosted on the internet.</p> </li> <li> <p>Domain name (google)</p> </li> <li> <p>Top-level domain name (.com)</p> </li> </ul> <p>However, many website URLs we encounter today contain a third-level domain, a second-level domain, and a top-level domain.</p> <ul> <li> <p>Top-level domain are .com, .edu, .gov, etc.</p> </li> <li> <p>Domain name (second-level domain) are google, wikipedia, etc.</p> </li> <li> <p>Third-level domain are <a href="http://map.google.com">map.google.com</a> for example</p> </li> </ul> <p>The root name server will redirect it to the <strong>.com</strong> domain name server. <strong>.com</strong> name server will redirect it to the [<strong>google.com](http://google.com)</strong> name server. The [<strong>google.com](http://google.com)</strong> name server will find the matching IP address for [<strong>maps.google.com](http://maps.google.com)</strong> in its’ DNS records and return it to your DNS recursor, which will send it back to your browser.</p> <p><img src="https://cdn-images-1.medium.com/max/2464/0*t_dRx7pPzk7pc0pb" alt="Source: Red Hat"/></p> <h2 id="what-happens-when-you-type-a-url-into-your-browser">What happens when you type a URL into your browser?</h2> <p><img src="https://cdn-images-1.medium.com/max/2000/1*uGBZcU70veeXbA9LEtQXWw.png" alt=""/></p> <p>Okay, let’s go to the main part. When you enter a URL into the address bar:</p> <ul> <li>DNS will go look up the URL and find the correct IP address. Let’s say the DNS found the IP address for <a href="https://www.google.com">https://www.google.com</a> is 142.251.32.46. This IP address will be return to the client’s computer.</li> </ul> <p><strong>TCP/IP (Transmission Control Protocol):</strong></p> <ul> <li>This communication protocol will use the IP address we found to send the data to us. The client computer opens a TCP connection the server computer at the IP address we found. Then, to put it simple, our client computer sends a request to the server computer and the server computer retrieves the data back to our server computer (the website). That’s how you get all the front-end data (for example, index.html) of the website.</li> </ul> <p>For those curious in how TCP/IP works in-depth, TCP works in the three-way handshake process:</p> <ul> <li> <p>Step 1 (SYN): The client wants to establish a connection with a server so it sends a segment with SYN (Synchronize Sequence number) which inform that the client wants to establish a connection to the server.</p> </li> <li> <p>Step 2 (SYN + ACK): Server responds to to the client request with SYN-ACK signal bits set. ACK (acknowledgment) signifies the response of the segment it received and SYN signifies with what sequence nuymber it is likely to start the segment with. This steps also require the server to have open ports that can accept and initiate new connections. A ports acts as a virtual endpoint that allows multiple services to run on the same device while keeping the communication organized.</p> </li> <li> <p>Step 3 (ACK): Both client and server establish a connection and will begin the data transfer.</p> </li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2000/0*vYFHiTYAdDb47joc.jpg" alt="Source: Wallarm"/></p> <p>This is not to mention TCP/IP Model contains 5 layers:</p> <ul> <li> <p>Application layer (what service you are using: web or email for example)</p> </li> <li> <p>Transport layer (reliable (TCP) or unreliable but faster connection (UDP) — mostly use for live stream, video calls)</p> </li> <li> <p>Network/Internet layer (logical addressing for devices on a network)</p> </li> <li> <p>Data link layer(error detection and correction for data being transmitted over a network)</p> </li> <li> <p>Physical layer (transmits bits over a physical medium such as cable or wireless signal)</p> </li> </ul> <h2 id="https-request">HTTP/S request</h2> <p>Once the TCP connection is established, let’s tranfer data! The browser will send a GET request asking for <a href="http://www.google.com">www.google.com</a> web page. You can also send POST request to websites that requires something like entering credentials or submitting a form.</p> <p>The server, which contains a webserver such as Apache will receives the request from the browser and passes it to a request handler to read and generate a response. The request handler is a program (written in <a href="http://ASP.NET">ASP.NET</a>, PHP, Ruby, etc.) that reads the request, its’ headers, and cookies to check what is being requested and also update the information on the server if needed. Then it will assemble a response in a particular format (JSON, XML, HTML). (Maneesa)</p> <p><strong>HTTP/S response:</strong></p> <p>The server response contains the web page you requested as well as the status code, compression type (<em>Content-Encoding)</em>, how to cache the page (<em>Cache-Control</em>), any cookies to set, privacy information, etc. (Maneesa)</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*ya9XkMmOWefY4mq8.png" alt=""/></p> <p>If you look at the above response, the first line shows a status code. This is quite important as it tells us the status of the response. There are five types of statuses detailed using a numerical code.</p> <p>● 1xx indicates an informational message only</p> <p>● 2xx indicates success of some kind</p> <p>● 3xx redirects the client to another URL</p> <p>● 4xx indicates an error on the client’s part</p> <p>● 5xx indicates an error on the server’s part</p> <p>So, if you encountered an error, you can take a look at the HTTP response to check what type of status code you have received. You can also use Postman to check the status of HTTP response.</p> <p><img src="https://cdn-images-1.medium.com/max/2864/0*cukuZ-3iIKY3-wXS.jpg" alt="Postman Learning Center"/></p> <h2 id="displaying-the-html-content">Displaying the HTML Content</h2> <p>The browser displays the HTML content in phases. First, it will render the bare-bone HTML skeleton. Then it will check the HTML tags and send out GET requests for additional elements on the web page, such as images, CSS stylesheets, JavaScript files, etc. These static files are cached by the browser, so it doesn’t have to fetch them again the next time you visit the page. In the end, you’ll see <a href="http://www.google.com">www.google.com</a> appearing on your browser. (Maneesa)</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*SmWIbPqyBZeZwais.jpg" alt="PCMag"/></p> <h2 id="how-we-can-use-cloud-services-such-as-awsgcpazure-terraform-kubernetes-and-docker-in-this-example">How we can use cloud services such as AWS/GCP/Azure, Terraform, Kubernetes, and Docker in this example?</h2> <p>Now let’s say you have built your own front-end with ReactJS/NextJS, pure JavaScript/HTML/CSS, etc. You want to deploy it on the Internet and get a domain so anyone can access your website online. I will keep these steps simple as our blog post is long already.</p> <p><img src="https://cdn-images-1.medium.com/max/2036/1*dW4xFlkCqpoaanQp9Msccw.png" alt=""/></p> <h2 id="step-1-server">Step 1: Server</h2> <p>For every front end, you need a server to run your website online. Luckily, cloud providers such as AWS/GCP/Azure all offer automatic scaling so you don’t have to worry about scaling your website. (We will talk more about scaling — specifically</p> <ul> <li> <p>vertical scaling (scaling up): increase the capacity of a single resource, such as a server or a virtual machine, by adding more power, memory, or storage to handle increased workload or demand</p> </li> <li> <p>horizontal scaling (scaling out): add more instances or copies of a resource, such as servers or virtual machines, to distribute the workload and increase the overall capacity</p> </li> <li> <p>load balancing: a technique used to distribute incoming network traffic across multiple servers or resources to ensure efficient utilization and improve performance.</p> </li> </ul> <p>in another blog). This is not to mention add-ons feature such as analytics, and storage, database offered by these cloud providers.</p> <p><img src="https://cdn-images-1.medium.com/max/3200/0*s6oHb5Xw7h8NE_o0.png" alt="K21Academy"/></p> <h2 id="step-2-docker-and-kubernetes">Step 2: Docker and Kubernetes</h2> <ul> <li> <p>Docker: Docker helps you pack everything you need to build your front-end site including libraries and settings into a single container.</p> </li> <li> <p>Kubernetes: Let’s say you have multiple containers, which hold your applications and distribute them across different computers called nodes. Kubernetes ensures that the containers are running correctly, monitors their health, and handles the situation if something goes wrong like crashing.</p> </li> </ul> <p>We use Docker and Kubernetes to package your application and deploy it on the server. It would require some DevOps skills to deploy a container onto the server.</p> <p><img src="https://cdn-images-1.medium.com/max/3200/0*YECr1A17-nSBwbu7.png" alt="Docker"/></p> <h3 id="more-on-devops">More on DevOps</h3> <p><img src="https://cdn-images-1.medium.com/max/2000/0*EBeWXRpf-N6UejFa.png" alt="Cl"/></p> <p>An example of DevOps CI/CD is when we push a commit to our desired Git and version control platform (Github, Gitlab, BitBucket, etc), which contains our</p> <ul> <li>Dockerfile (contains instructions to install and run the website like how we did with the front-end).</li> </ul> <p>Example of Dockerfile</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
    <span class="c"># Use a base image</span>
    FROM python:3.9-alpine
    
    <span class="c"># Set the working directory</span>
    WORKDIR /app
    
    <span class="c"># Copy the requirements file</span>
    COPY requirements.txt .
    
    # Install dependencies
    RUN pip install --no-cache-dir -r requirements.txt
    
    <span class="c"># Copy the application code</span>
    COPY app.py .
    
    # Expose a port
    EXPOSE 8000
    
    <span class="c"># Set the command to run the application</span>
    CMD ["python", "app.py"]

</code></pre></div></div> <ul> <li>Kubernetes file (YAML) to run the Docker image.</li> </ul> <p>Example of Kubernetes file (YAML)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: my-app-image:latest
          ports:
            - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
</code></pre></div></div> <p>We want for every commit pushed, the new version of the site will be deployed on the server automatically. Most cloud providers have their own CI/CD tool (AWS Code Pipeline, Google Cloud Build, Azure DevOps, etc.)</p> <p>We can configure the stages into these steps:</p> <ul> <li> <p>Source: Configure CodePipeline to monitor your GitHub repository as the source and pull the latest code changes.</p> </li> <li> <p>Build: Use a build stage (e.g., AWS CodeBuild) to build your Docker image based on the Dockerfile.</p> </li> <li> <p>Test: Include testing steps in your pipeline to verify the integrity and quality of your application.</p> </li> <li> <p>Deploy: Use a deployment stage to deploy the Docker image to your Kubernetes cluster. This stage will update the Kubernetes Deployment with the new image version.</p> </li> </ul> <p>Lastly, set up deployment triggers in your Kubernetes cluster to detect changes in the Deployment and automatically deploy the updated Docker image to your EC2 instance.</p> <h2 id="step-3-networking">Step 3: Networking</h2> <p>Once the website is deployed on the server, the server will return a public IP address of the server. You can also access the website via this IP address.</p> <h2 id="step-4-find-a-domain">Step 4: Find a domain</h2> <p>Buying a domain from sites such as CloudFlare, and Google Domain and connecting the IP address with the domain we just bought.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*c9JqXmzDqdeXO4oSYHmyFQ.png" alt="CloudFlare"/></p> <p>That’s it! Now everyone can access your website with this new domain you just bought.</p> <h2 id="optional-terraform">Optional: Terraform</h2> <p>Most of the time, creating Cloud infrastructure such as servers, VPC, storage, etc., and connecting them all together as well as destroying them will take a lot of time. Terraform is an open-source infrastructure as code (IaC) that helps you manage and provision your cloud resources in simple a consistent way. We won’t go too much on Terraform today but with the configurations you have in Terraform, you can create and deploy those whole processes with just a few lines of commands.</p> <p>Note: You might need VPC (Virtual Private Cloud) when working with Cloud providers. A VPC allows you to create a logically isolated section of the cloud where you can launch and connect resources like virtual machines, databases, and containers.</p> <p><img src="https://cdn-images-1.medium.com/max/3200/0*5uyGXjF-LL3Y2E0d.png" alt="Terraform"/></p> <p>Example of Terraform code:</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="s">provider "aws" {</span>
      <span class="s">region = "us-west-2"</span>
    <span class="s">}</span>
    
    <span class="s">resource "aws_instance" "example" {</span>
      <span class="s">ami           = "ami-0c94855ba95c71c99"</span>   <span class="c1"># Replace with your desired AMI ID</span>
      <span class="s">instance_type = "t2.micro"</span>
      <span class="s">key_name      = "your_key_pair_name"</span>      <span class="c1"># Replace with your key pair name</span>
    
      <span class="s">tags = {</span>
        <span class="s">Name = "example-instance"</span>
      <span class="s">}</span>
    <span class="s">}</span>
</code></pre></div></div> <p>Deploying your website is definitely a prolonged process. It makes me wonder how far we have come to have the websites loaded within seconds. I hope this article will help you understand more about the behind processes when we enter the URL into the address bar.</p> <p>Feel free to like, comment or share this article if it was helpful:)</p> <h2 id="references">References:</h2> <p>Wijesinghe-Nelken, Maneesa. “What Happens When You Type a URL in the Browser and Press Enter?” <em>Medium</em>, 3 Jan. 2020, medium.com/p/bb0aa2449c1a.</p>]]></content><author><name></name></author><category term="cloud"/><category term="cloud"/><category term="networking"/><summary type="html"><![CDATA[What happens when you type a URL into your browser?]]></summary></entry><entry><title type="html">Visualize your data from cloud with DoubleCloud and ClickHouse DB</title><link href="https://christopherle.com//blog/2023/clickhouse/" rel="alternate" type="text/html" title="Visualize your data from cloud with DoubleCloud and ClickHouse DB"/><published>2023-03-05T13:56:00+00:00</published><updated>2023-03-05T13:56:00+00:00</updated><id>https://christopherle.com//blog/2023/clickhouse</id><content type="html" xml:base="https://christopherle.com//blog/2023/clickhouse/"><![CDATA[<h2 id="visualize-your-data-from-cloud-with-doublecloud-and-clickhouse-db">Visualize your data from cloud with DoubleCloud and ClickHouse DB</h2> <p>Today, I will introduce to you a new platform I found for integrating your Cloud provider (AWS, GCP, Azure) and visualizing the data: DoubleCloud.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*F7S-_NfF_4LWk14v-PbM-Q.png" alt="Visualization of DoubleCloud workflow"/></p> <p>For those who don’t know, DoubleCloud is a new platform that helps you build sub-second data analytical solutions and pipelines on proven open-source technologies like ClickHouse® and Apache Kafka®.</p> <p>The reason why I wrote about this tool was the same reason I found visualizing data from cloud providers automatically can be a bit hassle. Of course, there are other players in this function too like AWS QuickSight, Tableau, etc. However, I believe that this particular new tool offers unique features, and DB options, that make it worth considering for anyone who regularly works with data from cloud providers.</p> <p><img src="https://cdn-images-1.medium.com/max/3600/0*YUHFTfwuWOdphc_B.jpg" alt="DoubleCloud Logo"/></p> <p>For your inquiries:</p> <p><img src="https://cdn-images-1.medium.com/max/2800/0*n39rgloE4aHnh3B3" alt="ClickHouse"/></p> <blockquote> <p>ClickHouse is a powerful and high-performance database management system designed for real-time data processing and analysis. It was originally created by Yandex, a Russian search engine, to support their web analytics platform called Metrica. Compared to other database providers, ClickHouse is an open-source software that uses a columnar data model to store and retrieve data. This means that data is stored in columns rather than rows, which allows for faster query processing and data compression. ClickHouse is particularly well-suited for OLAP workloads, where complex queries are executed on large datasets. It supports SQL-like query language and allows for real-time data processing and analysis, making it ideal for applications that require fast and accurate insights from large volumes of data.</p> </blockquote> <p><img src="https://cdn-images-1.medium.com/max/2000/0*FgyBIh3kI-pue7Go.png" alt="Apache Kafka"/></p> <blockquote> <p>Apache Kafka is a software platform that facilitates the distributed processing of large volumes of data streams in real-time. It is an open-source system that allows companies to build high-performance data pipelines, real-time data processing systems, and streaming analytics applications at scale. Apache Kafka allows users to publish, subscribe to, store, and process streams of records in real-time. It is designed to handle large volumes of data efficiently, allowing users to process data as it arrives, without the need to wait for it to be fully collected or batched. One of the key benefits of Apache Kafka is its ability to handle large-scale data processing tasks across multiple nodes in a distributed environment. It provides high availability and fault tolerance, ensuring that data streams are processed consistently and reliably.</p> </blockquote> <p>In this blog, we will use ClickHouse as our main DB connection.</p> <h2 id="table-of-content">Table of content</h2> <ol> <li> <p>Preparing our dataset</p> </li> <li> <p>Create Cluster — Setting up DoubleCloud</p> </li> <li> <p>Transfer — Create a connection between your AWS S3 Database and ClickHouse</p> </li> <li> <p>Visualize your dataset</p> </li> </ol> <h2 id="preparing-our-dataset">Preparing our dataset</h2> <h3 id="getting-the-data">Getting the data.</h3> <p>In this blog, we will use the layoff dataset from my previous <a href="https://medium.com/@locvicvn1234/analysis-of-current-layoffs-in-the-usa-with-tableau-a8b1077a16b4">blog</a>. You can get it <a href="https://www.kaggle.com/datasets/swaptr/layoffs-2022">here</a> from Kaggle (FYI, you might need to log in to download the dataset). The dataset will be named “layoffs.csv”</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*3C_uxIJCNDb_SvMm6alQ8A.png" alt="What the layoffs dataset will look like"/></p> <h3 id="uploading-the-dataset-to-aws-s3-bucket">Uploading the dataset to AWS S3 Bucket</h3> <p>As of now, DoubleCloud offers connections with AWS so we will use AWS as our endpoint.</p> <p>To upload your dataset to AWS S3 Bucket, you need to:</p> <ol> <li> <p>Sign in to the AWS Management Console and open the Amazon S3 console at <a href="https://console.aws.amazon.com/s3/">https://console.aws.amazon.com/s3/</a>.</p> </li> <li> <p>In the left navigation pane, choose <strong>Buckets</strong>.</p> </li> <li> <p>Choose <strong>Create bucket</strong>.</p> </li> <li> <p>The <strong>Create bucket</strong> page opens.</p> </li> <li> <p>For <strong>Bucket name</strong>, enter a name for your bucket. For now, let’s name it <strong>doublecloudtest</strong></p> </li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2180/1*KTezo2EaR5yRwiD6t0Nz-g.png" alt="Create AWS S3 bucket"/></p> <ol> <li>Once your bucket is created, upload your dataset “layoffs.csv” from your local computer.</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*jmT4AVYMjNLSSPzk-zZbXw.png" alt=""/></p> <ol> <li>The result should be like this.</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2594/1*1zRq14f-1ObbeA_ytZnK7Q.png" alt=""/></p> <p>More on creating AWS S3 Bucket from <a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/create-bucket-overview.html">here</a>.</p> <p>Note that, this tutorial only focuses on csv file. In real life, you might configure for the real-time database.</p> <h2 id="setting-up-doublecloud">Setting up DoubleCloud</h2> <ol> <li>First, you need a Managed ClickHouse® cluster.</li> </ol> <ul> <li> <p>To do this, create or log in to your account. Go to <a href="https://auth.double.cloud/login?client_id=yc.oauth.doubleconsole&amp;redirectUrl=https%3A%2F%2Fauth.double.cloud%2Foauth%2Fauthorize%3Fresponse_type%3Dcode%26client_id%3Dyc.oauth.doubleconsole%26scope%3Dopenid%26redirect_uri%3Dhttps%253A%252F%252Fapp.double.cloud%252Fauth%252Fcallback%26state%3DzoCg90o7ZO5lqMfsOrJyGXwT7ASzFcMEr9s31ms">console</a>.</p> </li> <li> <p>Create a Cluster with ClickHouse service. Let’s name it “doublecloud1” for now</p> </li> <li> <p>At this moment, DoubleCloud is supporting AWS. We will choose AWS as our data source now.</p> </li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2000/1*ZyEYkoVG4TgE4400DbgmYA.png" alt="Creating cluster with DoubleCloud"/></p> <ul> <li>For now, we will use default settings for our tutorial. Click submit to create a cluster. Once your cluster is done, the status will be Alive.</li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2246/1*79YwG1q5XvSFVRZymZfGtA.png" alt=""/></p> <h2 id="create-a-database-on-the-newly-created-cluster">Create a database on the newly created cluster</h2> <ol> <li> <p>Install ClickHouse.</p> <h1 id="for-macos">For MacOS</h1> <p>curl https://clickhouse.com/ | sh</p> <h1 id="for-linux">For Linux</h1> <p>curl https://clickhouse.com/ | sh sudo ./clickhouse install</p> </li> <li> <p>Go to your Cluster detail on DoubleCloud, copy the native interface code, and run in the terminal. It should look like this:</p> <blockquote> <p>clickhouse-client — host <strong>**</strong><strong>**</strong><strong>**</strong><strong>**<em>.at.double.cloud — port **** — secure — user admin — password **</em></strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><em>**</em></p> </blockquote> </li> </ol> <p>Notice that you might change the code due to recent ClickHouse’s update.</p> <blockquote> <p>./clickhouse client — host <strong>**</strong><strong>**</strong><strong>**</strong><strong>**<em>.at.double.cloud — port **** — secure — user admin — password **</em></strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><strong>**</strong><em>**</em></p> </blockquote> <p><img src="https://cdn-images-1.medium.com/max/2146/1*J_NAMvneP15HP7IfHaoUzQ.png" alt="Cluster detail interface"/></p> <blockquote> <p>Note that you will need to save the <strong>user, **and **password</strong> information elsewhere for later usage in the transfer.</p> </blockquote> <ol> <li>Create a database from your terminal <blockquote> <p>create database [YOUR_DATABASE_NAME] on CLUSTER [DOUBLECLOUD_CLUSTER_NAME]</p> </blockquote> </li> </ol> <p>where:</p> <ul> <li> <p>YOUR_DATABASE_NAME: the name you want for your database. Let’s do it Sample-ClickHouse-DB for now</p> </li> <li> <p>DOUBLECLOUD_CLUSTER_NAME: The name of your DoubleCloud cluster, which is “TestCluster” for now.</p> </li> </ul> <h2 id="create-a-connection-between-your-aws-s3-database-and-clickhouse">Create a connection between your AWS S3 Database and ClickHouse</h2> <ol> <li> <p>Go to <strong>Transfer</strong>.</p> </li> <li> <p>Go to <strong>Endpoints.</strong></p> </li> </ol> <h3 id="for-source">For source:</h3> <ol> <li> <p>Click <strong>Create endpoint</strong>, choose <strong>Source</strong></p> </li> <li> <p>Choose <strong>AWS S3</strong> as your source</p> </li> <li> <p>Choose a name of your choice. For now, let’s name it <strong>s3-source-quickstart</strong></p> </li> <li> <p>Configure your endpoint parameters:</p> </li> </ol> <ul> <li> <p>Dataset is <strong>layoffs</strong></p> </li> <li> <p>path pattern is <strong>*csv</strong></p> </li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2000/1*5yl2zfenjgInxjmN_sXNzA.png" alt=""/></p> <ol> <li> <p>In the <strong>S3: Amazon Web Services</strong>, enter your bucket name, AWS Access Key ID, and AWS Secret Access Key.</p> </li> <li> <p>Submit.</p> </li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*ofJWRQXWHQ68U2XhL8EQcg.png" alt=""/></p> <h3 id="to-get-your-aws-access-key-id-and-secret-access-key">To get your AWS access key ID and secret access key</h3> <ol> <li> <p>Open the IAM console at <a href="https://console.aws.amazon.com/iam/">https://console.aws.amazon.com/iam/</a>.</p> </li> <li> <p>On the navigation menu, choose <strong>Users</strong>.</p> </li> <li> <p>Choose your IAM user name (not the check box).</p> </li> <li> <p>Open the <strong>Security credentials</strong> tab, and then choose <strong>Create access key</strong>.</p> </li> <li> <p>To see the new access key, choose <strong>Show</strong>. Your credentials resemble the following:</p> </li> </ol> <ul> <li> <p>Access key ID: AKIAIOSFODNN7EXAMPLE</p> </li> <li> <p>Secret access key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</p> </li> </ul> <ol> <li>To download the key pair, choose <strong>Download .csv file</strong>. Store the .csv file with keys in a secure location.</li> </ol> <h3 id="for-target">For target</h3> <ol> <li> <p>Click <strong>Create endpoint</strong>, choose <strong>Target</strong></p> </li> <li> <p>Choose <strong>ClickHouse</strong> as your target</p> </li> <li> <p>Choose a name of your choice. For now, let’s name it <strong>clickhouse-target-quickstart</strong></p> </li> <li> <p>Configure your endpoint parameters:</p> </li> </ol> <ul> <li> <p>Database is <strong>Sample-ClickHouse-DB</strong></p> </li> <li> <p>Pass your user and password from your Cluster information.</p> </li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2000/1*sdhUtfZWExJVMO_yjGiVaA.png" alt=""/></p> <ol> <li> <p>Leave the rest for the default settings.</p> </li> <li> <p>Submit.</p> </li> </ol> <h3 id="test-the-connection">Test the connection</h3> <p>Once source and target endpoints are created, go back to the transfers tab and choose <strong>Activate.</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2170/1*QnTNVVjiAUGqDc9mmcX6xQ.png" alt=""/></p> <p>If the status is <strong>Done</strong>, the connection is successful.</p> <p>If the status is <strong>Error</strong> with the red color, click on the Error, then <strong>Logs</strong>, to see the error message. Usually, double-check if you already entered all the correct credentials from ClickHouse and AWS.</p> <h2 id="visualize-your-dataset">Visualize your dataset</h2> <ol> <li> <p>Go to <strong>Visualization</strong>.</p> </li> <li> <p>Create a new <strong>workbook</strong>. Let’s name it Demo Workbook.</p> </li> <li> <p>Create a new <strong>connection</strong>. Choose <strong>ClickHouse.</strong> The interface will ask for Hostname, Username and Password.</p> </li> <li> <p>Go to your cluster from Clusters, and go to <strong>Hosts</strong> to obtain host information</p> </li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2116/1*uUUdIhTNY7buxLO6JRdu_Q.png" alt=""/></p> <ol> <li>Copy host, username, and password in the Connection.</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*c9i16hS1Xjg1ZmuEsqCF3Q.png" alt=""/></p> <ol> <li> <p><strong>Check connection</strong>. If there is a green tick then <strong>Create connection.</strong></p> </li> <li> <p>Create dataset. Select the layoffs dataset.</p> </li> </ol> <p>You might see the column is combined as a string instead of separate columns.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*2FUvjYr0AvgMPAjgp3DTcA.png" alt=""/></p> <p>While this is a small issue, to handle this, we create a new <strong>field</strong>. Let’s name it the <strong>company</strong> for example. There, we split the combined string with “,” and select the first index returned from the split array, which is the company name. Choose <strong>formula</strong>, then enter this below</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SPLIT([company,location,industry,total_laid_off,percentage_laid_off,date,stage,country,funds_raised], ",", 1)
</code></pre></div></div> <p><img src="https://cdn-images-1.medium.com/max/2000/1*QgXt-H-y_EJ9fuRrpNMQ4A.png" alt="After spliting company name, the result will be like this"/></p> <p>Click <strong>save</strong>. Do the same for other columns you want to add. Remember to change to the corresponding type (string, integer, fractional number, etc).</p> <p>For now, let’s create 2 new fields with <strong>industry (index 3)</strong>, and <strong>total_laid_off (index 4)</strong> for simple visualization.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// industry
SPLIT([company,location,industry,total_laid_off,percentage_laid_off,date,stage,country,funds_raised], ",", 3)

// total_laid_off
SPLIT([company,location,industry,total_laid_off,percentage_laid_off,date,stage,country,funds_raised], ",", 4)
</code></pre></div></div> <ol> <li> <p>Once the database preparation is done, click <strong>create chart</strong></p> </li> <li> <p>Drop <strong>total_laid_off in Y</strong>, and <strong>industry in X.</strong> The result will be as below.</p> </li> </ol> <p><img src="https://cdn-images-1.medium.com/max/3548/1*E9b949iDj6MaD5gaL1v9ww.png" alt=""/></p> <h2 id="conclusion">Conclusion</h2> <p>If you reach this far, congratulations! You just learned to visualize your data from the cloud provider (AWS S3) with DoubleCloud and ClickHouse.</p> <p>My thought on this new platform is that it is very simple to use: the visualization tool with drag and drop reminds me of Tableau. Meanwhile, the simple experience to connect with data from a cloud provider with no code is impressive. Really looking forward to seeing how DoubleCloud goes in the future with more Cloud options from GCP and Azure.</p> <h2 id="references">References</h2> <iframe src="https://medium.com/media/e72cf162a23a457b10900eea98aa9093" frameborder="0"></iframe> <ul> <li> <p>AWS S3 Documentation</p> </li> <li> <p>AWS IAM Documentation</p> </li> <li> <p>DoubleCloud Documentation</p> </li> <li> <p>ClickHouse Documentation</p> </li> </ul>]]></content><author><name></name></author><category term="demo"/><category term="cloud"/><category term="demo"/><summary type="html"><![CDATA[Visualize your data from cloud with DoubleCloud and ClickHouse DB]]></summary></entry><entry><title type="html">Analysis of Current Layoffs in the USA with Tableau</title><link href="https://christopherle.com//blog/2022/tableu-layoffs/" rel="alternate" type="text/html" title="Analysis of Current Layoffs in the USA with Tableau"/><published>2022-11-21T14:56:00+00:00</published><updated>2022-11-21T14:56:00+00:00</updated><id>https://christopherle.com//blog/2022/tableu-layoffs</id><content type="html" xml:base="https://christopherle.com//blog/2022/tableu-layoffs/"><![CDATA[<h2 id="analysis-of-current-layoffs-in-the-usa-with-tableau">Analysis of Current Layoffs in the USA with Tableau</h2> <p>When you thought the pandemic was over, the year 2022 hit with a recession with most tech giants doing layoffs. Today’s post will be some of the insights I gained when doing personal exploratory data analysis on the tech layoff dataset. This analysis aims to have some insights into the current layoff situation and market. Therefore, we can somehow learn the cause, and what to prepare for in the future.</p> <p>Most of the visualizations are done by Tableau with data taken from <a href="https://www.kaggle.com/datasets/swaptr/layoffs-2022">Kaggle</a>, updated on Nov 21, 2022. These visualizations will be backed up with personal assumptions. Note that these personal observations came from my self-learning with Tableau. Please make any necessary suggestions if you think these can be improved.</p> <p>First, let’s look at the tech industries that were laid off in 2022. We can see the top three were retail, consumer, and transportation. I assumed that with the ongoing recession, people were more aware of controlling their consumption and transportation. Not to mention, the pandemic with remote work has motivated people to stay at home more often.</p> <p><img src="https://cdn-images-1.medium.com/max/4184/1*hCHuS5Wr9QTvpNSTxdzaiQ.png" alt=""/></p> <p>Compared to previous years, when you look at the year 2020 when the pandemic first happened, the top laid-off industries were transportation, travel, and finance. In 2021, these industries tended to have fewer layoffs. I assumed that people got used to the pandemic in 2021 and companies started to bounce back.</p> <p><img src="https://cdn-images-1.medium.com/max/4140/1*Dpo_BcpHVLk2kEuq0ffRbA.png" alt=""/></p> <p>Let’s have a look at the monthly trend from 2020 to 2022 to see what happened.</p> <p><img src="https://cdn-images-1.medium.com/max/3324/1*wHIbmy1qzQCbf-LnJIou1g.png" alt="Retail and consumer are the top 2 industries with the most laid-offs in 2022"/></p> <p>Those companies that laid off the most in 2022 were those at the IPO stage, followed by unknown, series C, and series B.</p> <p><img src="https://cdn-images-1.medium.com/max/4184/1*wUDUxieoXSSYL2JKZ84hYg.png" alt=""/></p> <p>Most laid-offs happened in the cities, especially in the West (SF Bay Area, Seattle, Los Angles). This contributes to the fact that most tech companies are located in the West.</p> <p><img src="https://cdn-images-1.medium.com/max/4184/1*cbZwcCDqmktRMvRSwE-fsw.png" alt=""/></p> <p>Undoubtedly, the top layoffs came from Meta and Amazon with 11,000 and 10,000 layoffs this year.</p> <p><img src="https://cdn-images-1.medium.com/max/4120/1*6R20lPdW3Fw-0k8AjQ4-Cw.png" alt=""/></p> <p>In terms of the funding raised in 2022, the media industry was the highest with a low laid-off value, with the major of funding being for Netflix. My assumption was that with the current pandemic, more and more people stayed at home and spent more time on movies, and streaming services.</p> <p><img src="https://cdn-images-1.medium.com/max/4184/1*KVc145_etG6COGrtbWWndA.png" alt=""/></p> <p>Let’s put funds raised and total laid-off in 2022 on a scatterplot to see their relationship. We can generally see that until Meta with a total fund raised of 26,000 million dollars, the higher the fund raised, the more company will lay off. After 26,000 million USD, it was hard to tell the relationship between funds raised and total laid-off.</p> <p><img src="https://cdn-images-1.medium.com/max/2824/1*fexfq15dN5s5MudlDxqkAg.png" alt=""/></p> <p>What I did, in addition, was to add clustering and averaging line with 95% CI to see the trend. The resulting trend was below. While it was hard to make sense of these groups (only the future will tell), I will leave this part for the readers to do a self-assessment.</p> <p><img src="https://cdn-images-1.medium.com/max/2360/1*5XTpdnWNiIhcZ_mPXbs8zA.png" alt=""/></p> <h2 id="what-i-learned-from-the-recession">What I learned from the recession</h2> <p>Remember last year, there were so many LinkedIn posts of people getting six-figure new grad offers from big tech companies. I assume that these companies were aiming for a come-back after the pandemic, therefore hiring as many engineers as possible to prepare for post-pandemic growth. However, that growth did not come with the unexpected recession. One of the best ways companies can right now survive is: to lay off people and focus on areas that show growth.</p> <p>With the massive layoffs from big tech, smaller companies will have more chances to attract talents with affordable costs, especially those who are under visa restriction. In other words, new grads in 2022 (and maybe 2023) will be likely to face great competition to get a job in tech.</p> <p>What I observed was that the world somehow always comes back to its balance and nothing is stable forever. The year 2021 came with massive tech hiring with tremendously high salaries and great visa support in STEM majors. This made more people want a career in tech. Therefore, finding and keeping a tech career is no longer easy. With more and more people learning coding interview techniques to get to companies, getting to top companies is no longer something impossible. Certainly, it is not easy to get there.</p> <p>What one can do is practice coding interviews frequently to prepare for any unexpected. After all, you cannot control external factors; You cannot predict the future nor you cannot change the past. It matters how would you react to the current situation.</p> <p><strong>So what can you do now?</strong></p> <ul> <li> <p>Control your budget, spending, and saving to prepare for what is coming next.</p> </li> <li> <p>Do your best at your current job to prevent being laid off. Also, remember to showcase your work/performance.</p> </li> <li> <p>However, practice coding interviews to prepare for a job search in case the uncontrollable happens.</p> </li> <li> <p>Review what you actually want (job with high salary, job that you like, or take some gap year for mental break, etc)</p> </li> <li> <p>Pick the jobs/industries/companies that are recession-proof. One way, in my opinion, is to see Maslow and the supply chain. What people always need first are physical and safety needs, meaning that you should pick the tech industries that are related to those categories. They may not give you a huge package but should you have some job security in mind first. Again, company research is needed.</p> </li> </ul> <p><img src="https://cdn-images-1.medium.com/max/2000/0*vL9x1MTy0fI7Rd-O" alt="Maslow and the supply chain"/></p> <h2 id="final-thoughts">Final thoughts</h2> <p>Let’s be honest. Job search is not easy. I remember last year, even before the recession, I found my first internship after +150 rejections. Although the recession may seem pretty bad for the tech job market now, especially for those under visa restrictions, it is also a good time for one to reflect on their values, practice coding interviews, control their budget wisely, or even spend more time with their loved ones. I do believe that at the end of the road, there will be a way. Keep looking! You got this!</p>]]></content><author><name></name></author><category term="AI"/><category term="tableau"/><category term="analytics"/><summary type="html"><![CDATA[Analysis of Current Layoffs in the USA with Tableau]]></summary></entry><entry><title type="html">Current reading books</title><link href="https://christopherle.com//blog/2022/reading/" rel="alternate" type="text/html" title="Current reading books"/><published>2022-11-21T13:56:00+00:00</published><updated>2022-11-21T13:56:00+00:00</updated><id>https://christopherle.com//blog/2022/reading</id><content type="html" xml:base="https://christopherle.com//blog/2022/reading/"><![CDATA[<ul> <li>System Design Interview pt1&amp;2</li> <li>Design Intensive Data Application</li> <li>SRE practices at Google</li> </ul>]]></content><author><name></name></author><category term="reading"/><category term="tech"/><summary type="html"><![CDATA[Current reading books]]></summary></entry><entry><title type="html">Almost all about that graph (part 1)</title><link href="https://christopherle.com//blog/2020/all-about-that-graph/" rel="alternate" type="text/html" title="Almost all about that graph (part 1)"/><published>2020-05-07T13:56:00+00:00</published><updated>2020-05-07T13:56:00+00:00</updated><id>https://christopherle.com//blog/2020/all-about-that-graph</id><content type="html" xml:base="https://christopherle.com//blog/2020/all-about-that-graph/"><![CDATA[<h2 id="algorithm-almost-all-about-that-graph-part-1">[Algorithm] Almost all about that graph (part 1)</h2> <h2 id="table-of-content">Table of content:</h2> <blockquote> <p><strong><em>I. Why graph</em></strong> <strong><em>II. What is graph</em></strong> <strong><em>III. Types of graph algorithms:</em></strong></p> </blockquote> <p>Part 1:</p> <blockquote> <p><em>1. Graph traversal (BFS, DFS)</em> <em>2. Finding the path with the lowest cost or shortest path</em> (besides BFS) <em>(Bellman-Ford, Dijkstra, Floyd-Warshall)</em></p> </blockquote> <p>Part 2:</p> <blockquote> <p><em>3. Minimum spanning tree (Prim, Union-Find)</em> <em>4. Sorting (Topological sort)</em> <strong><em>III. Example with a Leetcode problem</em></strong></p> </blockquote> <p>Part 3:</p> <blockquote> <p><strong><em>IV. Application in neural network — CNN (Building an image classification — Bonus topic)</em></strong> <strong><em>V. Conclusion</em></strong></p> </blockquote> <h2 id="i-why-graph">I. Why graph?</h2> <p>If you look closely at your smart phone’s applications or many other technical applications, the graph actually appears in every corner of our lives. From finding the shortest path from a location to another on Google Maps to graphing your connections on social media.</p> <p><img src="https://cdn-images-1.medium.com/max/2400/1*uCzI0jb4kaodm8uCiCmBng.jpeg" alt=""/></p> <p>Finding an optimal graph algorithm will reduce a great amount of cost or compute resources when applying graph with real life’s great amount of data like millions of real world’s streets (example of finding the shortest path on Google Map). (Well, unless you are trying to calculate the shortest distance between you and your crush’s heart, can’t help you with that 😅)</p> <h2 id="ii-what-is-a-graph-in-data-structure-and-algorithm">II. What is a graph (in data structure and algorithm)?</h2> <p><img src="https://cdn-images-1.medium.com/max/2000/1*_ZLmV0IH7_j8eQUrlG76hg.png" alt=""/></p> <ol> <li> <p>A graph is a set of vertices and a collection of edges that each connect a pair of vertices. (Sedgewick, Algorithms 518)</p> </li> <li> <p>There are two types of graph</p> </li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2066/1*6JnpO83tjoWVaiAeenfUmQ.png" alt=""/></p> <ol> <li>Loop and Multiple edges</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*m2YDWOeLmjWrKl3xI7R5Ug.png" alt=""/></p> <p>A <strong>loop</strong> is an edge that connects a vertex to itself. If a graph has more than one edge joining some pair of vertices then these edges are called <strong>multiple edges</strong>.</p> <ol> <li>Simple Graph</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*eZ6bBNttU8etFZ2m0Vgo1Q.jpeg" alt=""/></p> <p>A <strong>simple graph</strong> is a graph that does not have more than one edge between any two vertices and no edge starts and ends at the same vertex. In other words a simple graph is a graph without loops and multiple edges.</p> <ol> <li>Degree of a Vertex</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2560/1*0GmSMV_yuzTKPDnnk3KLJQ.jpeg" alt=""/></p> <p>6.Path</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*w01pdHWNDujdZoIRFh-Pfg.jpeg" alt=""/></p> <p>A <strong>path</strong> is a sequence of vertices with the property that each vertex in the sequence is adjacent to the vertex next to it. A path that does not repeat vertices is called a <strong>simple path</strong>.</p> <ol> <li>A Connected Graph</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*8aIjeWLKSAPqxg3khYTVlQ.jpeg" alt=""/></p> <p>A graph is said to be <strong>connected</strong> if <strong>any two</strong> of its vertices are joined by a path. A graph that is not connected is a <strong>disconnected graph</strong>. A disconnected graph is made up of connected subgraphs that are called <strong>components</strong></p> <ol> <li>Weight:</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*6R5gBfMBbqZb3J1SU0c28w.gif" alt=""/></p> <p>In a weighted graph, each vertex is assigned with a numerical value</p> <ol> <li>Adjacent matrix and Edge list representation:</li> </ol> <p><img src="https://cdn-images-1.medium.com/max/2000/1*UZcutROLuyQtYnOlrSVAlw.png" alt=""/></p> <h2 id="iii-types-of-graph-algorithm">III. Types of graph algorithm:</h2> <h3 id="1-graph-traversal"><strong>1. Graph traversal:</strong></h3> <p>Essential — BFS (breadth-first search) and DFS (depth-first-search)</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*GT9oSo0agIeIj6nTg3jFEA.gif" alt=""/></p> <p>DFS: begin from starting vertex to ending vertex, and repeat until all vertexes are covered.</p> <p>BFS: begin from starting vertex to all vertexes but level by level.</p> <p><strong>a. Breadth-first search:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*KAZbkOGxRrmTokzX6af2vA.gif" alt=""/></p> <p>Description: BFS is used to find the shortest path from a vertex to another (these vertexes should be connected) or path from 1 vertex to other vertexes in a graph.</p> <p>A great BFS demo by Sadanand Pai: <a href="https://sadanandpai.github.io/shortestpathfinder/">https://sadanandpai.github.io/shortestpathfinder/</a></p> <p>Detailed explanation: <a href="https://www.educative.io/edpresso/how-to-implement-a-breadth-first-search-in-python">https://www.educative.io/edpresso/how-to-implement-a-breadth-first-search-in-python</a></p> <p>Type of graph: undirected, directed, do not have weights (if not, weights are equal)</p> <p>Algorithmic use cases: finding the shortest path between two nodes, testing if a graph is bipartite, finding all connected components in a graph, etc.</p> <p>Complexity: O(V+E) — where V is the number of vertexes and E is the number of edges.</p> <p><strong>Code:</strong></p> <p>i. Implementing BFS:</p> <p><img src="https://cdn-images-1.medium.com/max/2860/1*-lsvcalsIgYjWi9SgPh-bA.png" alt=""/></p> <p>ii. Print path (2 methods):</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*Efb0roSG_ys7HU2IPDIuoA.png" alt=""/></p> <p>iii. Example usage:</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*gTiwg6QRb6ENcjOvmUOKmg.png" alt=""/></p> <p><strong>b. Depth-first search:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*qKBL47VFOJs4loXu1rVUDA.png" alt=""/></p> <p>Description: DFS is used to find a path from a vertex to another (these vertexes should be connected). DFS solution is not necessarily the shortest path.</p> <p>Detailed explanation: <a href="https://www.educative.io/edpresso/how-to-implement-depth-first-search-in-python">https://www.educative.io/edpresso/how-to-implement-depth-first-search-in-python</a></p> <p>Type of graph: undirected, directed</p> <p>Algorithmic use cases: topological sorting, solving problems that require graph backtracking, detecting cycles in a graph, finding paths between two nodes, finding an exit of a maze, etc.</p> <p>Complexity: O(V+E)</p> <p><strong>Code:</strong></p> <p>i. Implementation:</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*g5jpogk2frllkaLWX1a04g.png" alt=""/></p> <p>ii. Example usage:</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*G2mt-kGla_esyV7CslQEBg.png" alt=""/></p> <h3 id="2-finding-the-path-with-the-lowest-cost-or-shortest-path-besides-bfs"><strong>2. Finding the path with the lowest cost or shortest path (besides BFS):</strong></h3> <p><em>In this chapter, for each edge, there will be a weight (cost) between two vertexes.</em></p> <p>a. Bellman-Ford</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*SdJ4ZUD4XuiJEqORTJn2GQ.gif" alt=""/></p> <p>Description: [Single-source] To find the path with the <strong>lowest cost from one vertex to every other vertex. Can be used to detect negative-weight cycle</strong></p> <p>Detailed explanation: <a href="https://www.geeksforgeeks.org/bellman-ford-algorithm-simple-implementation/">https://www.geeksforgeeks.org/bellman-ford-algorithm-simple-implementation/</a></p> <p>Type of graph: undirected, directed, have weights, <strong>weights can be positive or negative</strong></p> <p>Complexity in this implementation: O(V.E)</p> <p><strong>Code:</strong></p> <p>i. Implementation:</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*tbvKRVJhFY3TEAt9cFWvpA.png" alt=""/></p> <p>ii. Example usage:</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*-ngNUkyehk0CndENE2pMjA.png" alt=""/></p> <p>b. Dijkstra</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*15KkonMRnHdbzGhFw0PXCA.gif" alt=""/></p> <p>Description: [Single-source] Dijkstra is used to <strong>finding a path with the lowest cost from one vertex to every other vertex.</strong></p> <p>Detailed explanation: <a href="https://www.bogotobogo.com/python/python_Dijkstras_Shortest_Path_Algorithm.php">https://www.bogotobogo.com/python/python_Dijkstras_Shortest_Path_Algorithm.php</a></p> <p>Type of graph: undirected, directed, have <strong>positive weights</strong></p> <p>Complexity: O(V²) — optimal: O(ElogV) with a heap (priority queue)</p> <p><strong>Code:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*dv3iuAL-dDWDgnFlBdQS7w.png" alt=""/></p> <p>c. Floyd-Warshall</p> <p><img src="https://cdn-images-1.medium.com/max/2000/1*CAa3Bt9rB_l5p8wjm_5puA.png" alt=""/></p> <p>Description: [All-pairs] Floyd-Warshall is used to finding the shortest path for all pairs of vertexes.</p> <p>Detailed explanation: <a href="https://www.programiz.com/dsa/floyd-warshall-algorithm">https://www.programiz.com/dsa/floyd-warshall-algorithm</a></p> <p>Brief explanation:</p> <blockquote> <p><em>Floyd-Warshall uses Dynamic Programming method to save initial results into an array. Then it will run a loop again to check middle vertexes and their cost between themselves and starting and ending vertex.</em> <em>If current cost &gt; (new cost 1 (start tonew vertex) + new cost 2 (new vertex to end))</em> <em>then the current cost will update itself with (new cost 1 + new cost 2)</em></p> </blockquote> <p>Type of graph: <strong>directed only, weights can be negative or positive, cannot be used in the negative cycle</strong></p> <p>Complexity: O(V³)</p> <p>Code:</p> <p>i. Implementation</p> <p><img src="https://cdn-images-1.medium.com/max/2720/1*00tbXgW3FYSk3AeTDTxkTw.png" alt=""/></p> <p>ii. Sample usage:</p> <p><img src="https://cdn-images-1.medium.com/max/3048/1*jcgP44jiNPWi0KYusf1Nig.png" alt=""/></p> <h2 id="summary">Summary:</h2> <p>Hope that this blog can help you understand more about graph algorithms and when to use them specifically.</p> <p>Here is the overview. Stay tuned for part 2.</p> <p>For better visualization, I strongly recommend this site: <a href="https://visualgo.net/en">https://visualgo.net/en</a></p> <p><img src="https://cdn-images-1.medium.com/max/3150/1*8O_GeY8kyb1M49NLJmOXBg.png" alt=""/></p> <h2 id="reference">Reference:</h2> <ol> <li> <p>Sedgewick, R., Wayne, K. (2011). <em>Algorithms, 4th Edition</em>. Addison-Wesley. ISBN: 978–0–321–57351–3</p> </li> <li> <p>CS 97SI: Introduction to Programming Contests from Stanford University</p> </li> <li> <p>Big-O Coding Algorithm Class</p> </li> </ol> <p>For any questions or concerns, please contact me at locvicvn1234@gmail.com</p> <p>My LinkedIn: <a href="https://www.linkedin.com/in/chrislevn/">https://www.linkedin.com/in/chrislevn/</a></p> <p>My Coding Challenges: <a href="https://github.com/chrislevn/Coding-Challenges">https://github.com/chrislevn/Coding-Challenges</a></p>]]></content><author><name></name></author><category term="tech"/><category term="algorithm"/><summary type="html"><![CDATA[Almost all about that graph (part 1)]]></summary></entry><entry><title type="html">Basic Algorithms in JavaScript (part 1)</title><link href="https://christopherle.com//blog/2020/basic-js-algorithms/" rel="alternate" type="text/html" title="Basic Algorithms in JavaScript (part 1)"/><published>2020-03-07T13:56:00+00:00</published><updated>2020-03-07T13:56:00+00:00</updated><id>https://christopherle.com//blog/2020/basic-js-algorithms</id><content type="html" xml:base="https://christopherle.com//blog/2020/basic-js-algorithms/"><![CDATA[<h2 id="basic-algorithms-in-javascript-part-1">Basic Algorithms in JavaScript (part 1)</h2> <p>Hi guys, long time no see!</p> <p>Recently, I decided to go back to learn about basic stuff in Computer Science such as Data Structures and Algorithms, Algebra, Statistics, etc. in order to process to Advanced Machine Learning and Deep Learning. I took a course on Udacity named “Data Structures and Algorithms” and decided to write weekly blogs from what I have learned about Algorithms (as well as Machine Learning) for you guys to better understanding the Computer Science and possibly prepare for the Coding Interview. Hope this helps!</p> <p>P/S: I tried my best to make this blog post as much comprehensive as possible. However, if you are in CS major and want to explore deeper in Algorithms, please do not hesitate to search for more resources. (Also, feel free to contact me if you have any questions/ideas, I am always eager to connect and discuss with you)</p> <p>-Christopher Le-</p> <p><strong>I. Steps needed to remember while solving algorithm problems:</strong></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. Clarify the question
2. Generate inputs and outputs
3. Generate test cases
4. Brainstorming
5. Run time analysis 
6. Coding
7. Debugging
</code></pre></div></div> <p>Remember to do all of them on whiteboard/paper or on computer but do not run the code</p> <p><strong>II. Quick review on some Data Structures’s concepts:</strong></p> <p><strong>1.Lists:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*y6PmQwXRauwMM79B" alt=""/></p> <p>Short description:</p> <p>“Lists” are one type of data structure, and can store multiple values. They are unique in how they pair data with “pointers”, the pointers indicating the next piece of data’s memory location. In lists, data is stored in various disjointed locations memory. Because data is stored in different locations, each piece of data can only be accessed through the pointer that precedes it.</p> <p><strong>2. Arrays:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*xn8lBxI-777HaXmW" alt=""/></p> <p>Short description:</p> <p>“Arrays” are one type of data structure, and can store multiple values. Each element can be accessed through its index (a number that denotes its order within the data). Data is stored sequentially in memory in consecutive locations. Because they are stored in consecutive locations, memory addresses can be calculated using their indices, allowing for random access of data. Another feature of arrays is that adding or deleting data in a specific location carries a high cost compared to lists.</p> <p><strong>3. Stacks:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*oF1dEn_3ELc-ZduH" alt=""/></p> <p>Short description:</p> <p>The structure of a stack can be easily imagined as a pile of objects stacked vertically. When extracting these objects, they are extracted from the top down as the rule “LIFO” (“Last In First Out”). We use the term “Push” to refer to the act of adding data to stack, and the term “Pop”, in opposite, to refer to the act of extracting data from the stack.</p> <p><strong>4. Queues:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*01knPi9lSfAmKhB-" alt=""/></p> <p>Short description:</p> <p>“Queues” are also known as “waiting lines” like a group of people waiting in line. The sooner a person lines up, the higher their priority. This is called “First In First Out” (FIFO). We use the term “enqueue” to refer to the act of adding data to a queue, and “dequeue” for the act of extracting data from a queue</p> <p><strong>5. Hash Tables:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*Ilm8tmxexw-Nl05S" alt=""/></p> <p>Short description:</p> <p>“Hash Tables” are good at storing data in sets made of “keys” and “values”. By searching and extracting a key, we can learn its corresponding value. Hash Tables solve the problem when it takes time to search through data stored in an array, which is inefficient.</p> <p><strong>6. Heaps:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*aGRHnLWpny0EWcvD" alt=""/></p> <p>Short description:</p> <p>“Heaps” are used when implementing a “priority queue”. In a priority queue, data can be added in any order. Conversely, when extracting data, the smallest values are chosen first. As for the rule of heaps, a child number is always greater than its parent number. If the parent number happens to be greater, the child and the parent swap. When extracting a number from a heap, the number on the top is removed (which is also the smallest).</p> <p><strong>7. Binary Search Trees (BST):</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*0Ko5tddbZe7GoGGp" alt=""/></p> <p>Short description:</p> <p>The numbered points are called “nodes”. Binary search trees have 2 properties: 1. All nodes are greater than the nodes in their left subtree; 2. All nodes are smaller than the nodes in their right subtree.</p> <p><em>Bonus: Binary search tree (BST)’s implementation:</em></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>**class** Node {

constructor(data) {

**this**.right = **null**;

**this**.left = **null**;

**this**.data = data; }

}
</code></pre></div></div> <p><strong>III. Basic Algorithms:</strong></p> <p><strong>A. Sort:</strong></p> <p>Problem: sort an array of unordered numbers</p> <p><strong>1.Bubble sort:</strong></p> <p>Short description: As the scale moves from right to left, it will compare 2 numbers. If left number is greater than right number, the position of them are swapped. If not, the scale keep moving left without swapping anything. The swapping continues until all numbers have been sorted</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*LibO3B16QPAb4tSj" alt=""/></p> <p>Implementation in Javascript:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>**function** BubbbleSort(array) {

**var** newArray = [];

**let** n = array.length;

**for** (**var** i = 0; i &lt; n - 1; i++) {

 ** for** (**var** j = 0; j &lt; n - i - 1; j++) {

 **   if** (array[j] &amp;gt; array[j + 1]) {

 **      var** temp = array[j];

         array[j] = array[j + 1];

    array[j + 1]= temp;

}

}

}

**return** newArray.concat(array)

}
</code></pre></div></div> <p>Run-time analysis: O(n²)</p> <p><strong>2. Selection sort:</strong></p> <p>Short description: The minimum of the array will be moved to the left. After each number is sorted, the algorithm calculates the next minimum value of the left-over array and move it to the left. The process continues until all values have been sorted.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*l3fljmGcBeiag0n_" alt=""/></p> <p>Implementation in Javascript:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>**function** SelectionSort(array) {

 ** for** (**var** i = 0; i &lt; array.length; i++) {

 **   let** min = i;

 **   for** (**var** j = i + 1; j &lt; array.length; j++) {

 **     if** (array[min] &amp;gt; array[j]) {

         min = j

       }

     }

 **    if** (i !== min) {

    [array[ i ],array[min]]= [array[min],array[ i ]];

     }

    }

 **  return** array;

}
</code></pre></div></div> <p>Run-time analysis: O(n²)</p> <p><strong>3. Merge sort:</strong></p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*avYld5ADA2xCBTwj" alt=""/></p> <p>Short description: The array is divided in groups of 2 until each values is separated individually. From each sub-box, the smallest value is compared with values from the next sub-box in order from left to right. After each sub-box is sorted, the process continues until it returns into a sorted array.</p> <p>Implementation in Javascript:</p> <p><strong>function</strong> MergeSort(array) {</p> <p><strong>if</strong> (array.length &lt; 2) {</p> <p><strong>return</strong> array;</p> <p>}</p> <p><strong>var</strong> middle = Math.floor(array.length / 2);</p> <p><strong>var</strong> left = array.slice(0, middle);</p> <p><strong>var</strong> right = array.slice(middle);</p> <p><strong>function</strong> merge(left, right) {</p> <p><strong>let</strong> newArray = [];</p> <p><strong>while</strong> (left.length &amp;&amp; right.length) {</p> <p><strong>if</strong> (left[0] &lt; right[0])</p> <p>{</p> <p>newArray.push(left.shift());</p> <p>} <strong>else</strong> {</p> <p>newArray.push(right.shift());</p> <p>}</p> <p>}</p> <p><strong>return</strong> newArray.concat(left, right);</p> <p>}</p> <p><strong>return</strong> merge(MergeSort(left), MergeSort(right));</p> <p>}</p> <p>Run-time analysis: O(nlog(n))</p> <p><strong>4. Quick sort:</strong></p> <p>In this case, last element is picked as pivot</p> <p>Short description:</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*NaGZWU6lsxqPfagN" alt=""/></p> <p>Implementation in Javascript:</p> <p><strong>function</strong> QuickSort(array) {</p> <p><strong>if</strong> (array.length &lt;= 1) {</p> <p><strong>return</strong> array;</p> <p>} <strong>else</strong> {</p> <p><strong>var</strong> left = [];</p> <p><strong>var</strong> right = [];</p> <p><strong>var</strong> newArray = [];</p> <p><strong>var</strong> pivot = array.pop();</p> <p><strong>var</strong> length = array.length;</p> <p><strong>for</strong> (<strong>var</strong> i = 0; i &lt; length; i++) {</p> <p><strong>if</strong> (array[i] &lt;= pivot) {</p> <p>left.push(array[i]);</p> <p>} <strong>else</strong> {</p> <p>right.push(array[i]);</p> <p>}</p> <p>}</p> <p><strong>return</strong> newArray.concat(QuickSort(left), pivot, QuickSort(right));</p> <p>}</p> <p>}</p> <p>Run-time analysis: O(nlog(n))</p> <p><strong>B. Search:</strong></p> <p>Problem: find a specific number in an array. If number is not found, return -1.</p> <p><strong>1.Linear search:</strong></p> <p>Short description: compare the number with each value in the array from lowest to highest index. The searching process stops when the number is found. If all values are gone through without locating the number, the algorithm return -1</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*Oy0l47GiGEIIDW_m" alt=""/></p> <p>Implementation in Javascript:</p> <p><strong>function</strong> LinearSearch(array, length, number)</p> <p>{</p> <p><strong>for</strong> (<strong>var</strong> i = 0; i &lt; n; i++)</p> <p>{</p> <p><strong>if</strong> (array[i] == x)</p> <p>{</p> <p><strong>return</strong> i;</p> <p>}</p> <p>}</p> <p><strong>return</strong> -1;</p> <p>}</p> <p>Run-time analysis: O(n)</p> <p><strong>2. Binary search:</strong></p> <p>Short description: The algorithm sorts the array then defines the range that the number maybe located in. This is more efficient as we don’t have to run through all values to search for the number.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*PxUxExNXKz7N9kSK" alt=""/></p> <p>Implementation in Javascript:</p> <p><strong>function</strong> BinarySearch(array, l, r, x)</p> <p>{</p> <p><strong>if</strong> (r &gt;= 1)</p> <p>{</p> <p><strong>var</strong> mid = 1 + (r -1 )/2;</p> <p><strong>if</strong> (array[mid] == x)</p> <p>{</p> <p><strong>return</strong> mid;</p> <p>}</p> <p><strong>else</strong> <strong>if</strong> (array[mid] &gt; x)</p> <p>{</p> <p><strong>return</strong> BinarySearch(array, 1, (mid -1 ), x);</p> <p>}</p> <p><strong>else</strong></p> <p>{</p> <p><strong>return</strong> -1;</p> <p>}</p> <p>}</p> <p>}</p> <p>Run-time analysis: O(log(n))</p> <p><strong>C. Graph:</strong></p> <p>Problem: find a path from A to G</p> <p><strong>1. Breadth — First Search (BFS) //Graph Search:</strong></p> <p>Short description: A -&gt; B -&gt; C -&gt; D -&gt; E -&gt; F -&gt; H -&gt; I -&gt; J -&gt; K -&gt; G</p> <p>From the parent, the process finishes searching in all nodes in a sub-parent before moving to next ones from left to right. The process continues until the destination is found.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*E4AZaXyy8ldLSsG-" alt=""/></p> <p>Implementation in Javascript (@chrisco’s approach):</p> <p><strong>function</strong> bfs(value, tree) {</p> <p>queue = [];</p> <p>queue.unshift(tree);</p> <p><strong>while</strong> (queue.length &gt; 0) {</p> <p>curNode = queue.pop();</p> <p><strong>if</strong> (curNode.value === value) {</p> <p><strong>return</strong> curNode;</p> <p>}</p> <p><strong>var</strong> len = curNode.children.length;</p> <p><strong>for</strong> (<strong>var</strong> i = 0; i &lt; len; i++) {</p> <p>queue.unshift(curNode.children[i]);</p> <p>}</p> <p>}</p> <p><strong>return</strong> <strong>null</strong>;</p> <p>}</p> <p>Run-time analysis: O(n²)</p> <table> <tbody> <tr> <td>Other approach’s run-time analysis: O(</td> <td>V</td> <td>)</td> </tr> </tbody> </table> <p><strong>2. Depth — First Search (DFS) //Graph Search:</strong></p> <p>Short description: A -&gt; B -&gt; E -&gt; C -&gt; F -&gt; K -&gt; D -&gt; H -G</p> <p>Like the name of the algorithm, DFS will search all nodes in terms of its depth of a parents from left to right. The process continues until the destination is found.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*SiH6CyhPd_ldQU8c" alt=""/></p> <p>Implementation in Javascript (@chrisco’s approach):</p> <p><strong>function</strong> dfs(value, node) {</p> <p>stack = [];</p> <p>stack.push(node);</p> <p><strong>while</strong> (stack.length != 0) {</p> <p><strong>var</strong> curNode = stack.peek()</p> <p><strong>if</strong> (curNode.value == value) {</p> <p><strong>return</strong> curNode;</p> <p>}</p> <p>curNode.visited = <strong>true</strong></p> <p>stack.push(getFirstUnvistedNode(curNode));</p> <p>}</p> <p>}</p> <p>Run-time analysis: O(n²)</p> <table> <tbody> <tr> <td>Other approach’s run-time analysis: O(</td> <td>V</td> <td>+</td> <td>E</td> <td>)</td> </tr> </tbody> </table> <p><strong>D. Other basic algorithm:</strong></p> <p><strong>1.Recursion — Example with Fibonacci problem:</strong></p> <p>Fibonacci sequence: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, … (each number is the sum of the two preceding ones, starting from 0 and 1)</p> <p>Problem: find Fibonacci value of nth element</p> <p><strong>function</strong> Fib(n)</p> <p>{</p> <table> <tbody> <tr> <td><strong>if</strong> (n == 0</td> <td> </td> <td>n == 1) { <strong>return</strong> 1;}</td> </tr> </tbody> </table> <p><strong>return</strong> Fib(n - 1) + Fib (n - 2)</p> <p>}</p> <p>Run-time analysis: O(1.618^(n+1))</p> <p><strong>2. Euclidian Algorithm — Example with Finding GCD Problem:</strong></p> <p>GCD: greatest common divisor</p> <p>Problem: find GCD of 2 numbers</p> <p><strong>function</strong> GCD(a, b) {</p> <p><strong>if</strong>(a === 0) { <strong>return</strong> b;}</p> <p><strong>if</strong>(b === 0) { <strong>return</strong> a;}</p> <p><strong>return</strong> GCD(b, a % b);</p> <p>}</p> <p>Run-time analysis: O(log(n)²)</p> <p>**Github: <a href="https://github.com/locvicvn/Algorithm">**https://github.com/locvicvn/Algorithm</a></p> <p><strong>What to expect in Basic Algorithms in Javascript (part 2):</strong></p> <ol> <li> <p>Dynamic Programming</p> </li> <li> <p>Shortest Path Problem</p> </li> <li> <p>Knapsack Problem</p> </li> <li> <p>Divide and Conquer</p> </li> <li> <p>Strings Keys</p> </li> <li> <p>Traveling Salesman Problem</p> </li> </ol> <p><strong>References:</strong></p> <ol> <li> <p>“Data Structure and Algorithms” course on Udacity — Course’s link: <a href="https://classroom.udacity.com/courses/ud513">https://classroom.udacity.com/courses/ud513</a></p> </li> <li> <p>HackerRank Coding Interview on Youtube — Playlist’s link: <a href="https://www.youtube.com/playlist?list=PLOuZYwbmgZWXvkghUyMLdI90IwxbNCiWK">https://www.youtube.com/playlist?list=PLOuZYwbmgZWXvkghUyMLdI90IwxbNCiWK</a></p> </li> <li> <p>Big-O Notation Cheatsheet: <a href="https://www.hackerearth.com/practice/notes/big-o-cheatsheet-series-data-structures-and-algorithms-with-thier-complexities-1/">https://www.hackerearth.com/practice/notes/big-o-cheatsheet-series-data-structures-and-algorithms-with-thier-complexities-1/</a></p> </li> <li> <p>Short descriptions’ credits: <a href="http://algorithm.wiki/">http://www.algorithm.wiki</a></p> </li> <li> <p>Credit for images: <a href="http://algorithm.wiki/">http://www.algorithm.wiki</a></p> </li> </ol> <p>-Christopher Le-</p>]]></content><author><name></name></author><category term="tech"/><category term="algorithm"/><summary type="html"><![CDATA[Basic Algorithms in JavaScript (part 1)]]></summary></entry><entry><title type="html">Will AI replace human labor?</title><link href="https://christopherle.com//blog/2019/will-ai-replace-human/" rel="alternate" type="text/html" title="Will AI replace human labor?"/><published>2019-08-10T13:56:00+00:00</published><updated>2019-08-10T13:56:00+00:00</updated><id>https://christopherle.com//blog/2019/will-ai-replace-human</id><content type="html" xml:base="https://christopherle.com//blog/2019/will-ai-replace-human/"><![CDATA[<h2 id="will-ai-replace-human-labor">Will AI replace human labor?</h2> <p>For those who don’t know about AI, AI is short for Artificial Intelligence and its hottest related jobs are Machine Learning, Data Science, and Deep Learning.</p> <p>(If you prefer short answer, scroll down to the bottom)</p> <p>Hi guys, long time no see!</p> <p>A little background from what I’m doing right now first.</p> <p>Last month, I had the chance to learn “Applied Machine Learning in Economics” from VSSR (Vietnamese Summer School in Research) taught by Ph.D. from University of Birmingham (UK) and Harvard University (U.S). In terms of the technological side, this three-day course and one-day project obviously cannot cover everything in Machine Learning. What I appreciated the most, however, was my ML teacher’s insightful perspectives about Machine Learning in today’s world as “the one with data is the one with the power to control”.</p> <p>Well, that’s actually correct! With data, companies will define people’s interests and predict their next goals for investments. With data, cooperations like Facebook, Youtube, or Lazada will control people’s consuming habits by continuously showing those “suggestions” on people’s posts. We machine learners and data scientists often joke about Son Tung M-TP, a very popular Vietnamese singer, as a data scientists not a singer due to the fact that he always knows his audience’s listening habits and produces music based on them.</p> <p>Statistically proven, Data Science (or Machine Learning) is one of the hottest keys as well as skillsets in job postings for the past 10 years (and yet, it is still growing). What hurts me is to see some people with different passions, expertise give up their current jobs to devote themselves to Data Science for the sake of being recruited.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*85pJi9ictLV4ohnO" alt=""/></p> <p>I mean, there is nothing wrong to learn about Tech, especially when it is so important in today’s development. However, it is not wise to risk your passion and expertise for something else for the sake of employment. Unless you have interests in Tech, your motives will be burn-out.</p> <p>In fact, from my experience doing Machine Learning project with people from different fields. I learned that in order to acquire data sense, a Machine Learning team cannot ignore the help of experts who can give you what features needed to be eliminated or kept. For example, let’s just say you are solving a HR problem of selecting who will get a promotion using Machine Learning. Although you might gather all the possible features (years of experience, test score, age, level of education, etc.), only HR experts from that company will know what they need, which also means which features are useful to create a model.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*cf8Y0SWcpnz7kY3v" alt=""/></p> <p>We can generate a Machine Learning workflow to something similar to this, with requires the help of Experts, Data Scientists, and Machine Learning Engineer (Data Scientists can be replaced if Experts know how to utilize Machine Learning or if Machine Learning Engineer have data sense and the ability to analyze data):</p> <ol> <li> <p>Define problems and goals. Experts, Data Scientists, and Machine Learning Engineer with finding the data together (preferred clean data, but that will be not the case in real life, so mostly requires data processing)</p> </li> <li> <p>Experts help eliminate some irrelevant features like ID, etc. (this depends)</p> </li> <li> <p>Data Scientists help visualize the data for better insights</p> </li> <li> <p>Experts help define useful features for training</p> </li> <li> <p>Finally, Machine Learning Engineers help train and test the model.</p> </li> </ol> <p>In other words, back to the main question “Will AI replace human works?” , I do not think so, not at this moment. Most Machine Learning works nowadays still requires support from experts due to the fact that Machine Learning/ Data Scientists are not always know-it-all people. Without experts, our models will be created based on pure assumptions.</p> <p>But wait, if AI cannot replace human, what is happening? Why according to Fortune, <a href="https://fortune.com/2019/01/10/automation-replace-jobs/">“A.I. Expert Says Automation Could Replace 40% of Jobs in 15 Years” </a>.</p> <p><img src="https://cdn-images-1.medium.com/max/2000/0*GxIZTIPm8sc2tqPs" alt=""/></p> <p>Theoretically, with the increasing computer’s capability according to Moore Law, most AI models nowadays can handle human works with greater automation’s capability in terms of dealing with large-scale data. In a more comprehensive way of explanation, computers/robots/AIs almost do not need to rest as much as a human but can still do a lot of automation or computation must faster than average human. That said, average workers, unless they learn to improve themselves, will mostly lose their jobs due to AI. This will inevitably happen as the world we are living in is not perfect; not everyone is a Ph.D. of their fields, concerning not everyone has chances to access education.</p> <p><strong>Short answer:</strong> Will AI replace human works? No, and at least at this moment when SAI (Super Artificial Intelligence) has not been born yet. AI models still need constant help from experts in their own fields to complete themselves, especially for some competitive tasks like generate music, artworks, self-driving car (in Vietnam <em>laugh</em>), etc.</p> <p>However, AI will replace most average works that relate to automation. The only way we, as human, in this 4.0 industry can do is to improve our knowledge and become experts in our fields. Your experts’ works, directly or not, will definitely create some impacts for people from the Tech industry. In easier words, imagine AI like a baby child, if people from Tech are responsible to create a wealthy child’s body, the works of experts will be the soul and knowledge to enable that child to fully functional.</p> <blockquote> <p>A message to non-tech people who are reading this post: Keep striving for knowledge and your expertise, your passion, things that can drive you forward in this competitive world. Don’t worry! If you are good enough, there will always rooms for your self-development.</p> </blockquote> <p>Cheers,</p> <p>Christopher Le</p>]]></content><author><name></name></author><category term="personal"/><category term="personal"/><category term="tech"/><summary type="html"><![CDATA[Will AI replace human labor?]]></summary></entry></feed>